# Part 3: How - どのように導入するのか

## 3.1 導入アプローチ：既存資産を拡張する段階的戦略

### 基本方針：スクラッチではなく拡張

**避けるべきアプローチ：**
- 既存システムを全て捨てて、AIエージェント基盤を一から構築
- 大規模な初期投資
- 長期間のシステム停止

**推奨するアプローチ：**
- 既存のRPA/Dify/APIをそのまま使う
- その上に「判断レイヤー」としてAIエージェントを追加
- 小さく始めて、効果を確認しながら拡大
- マチュリティモデルに沿って段階的に成長

---

<br>

## 3.2 実装ロードマップ：3つのPhase

### Phase 1：観察と学習（1-2ヶ月）

**目的：** AIエージェントが何をどう判断するかを理解する

**やること：**

1. **既存業務の「ツール化」準備**
   - 現在動いているRPAフローをリストアップ
   - それぞれが「何をするツール」かを言語化
   - 例：「請求書をシステムに登録するツール」

2. **AIエージェントの限定的導入（読み取り専用）**
   - まずは「判断だけ」させてみる
   - 実際の実行はまだ人間が確認してから
   - どんな判断をするかをログに記録

3. **パイロット業務の選定**
   - 失敗しても影響が小さい業務
   - 判断が必要だが定型的な業務
   - 例：「社内問い合わせの振り分け」「ドキュメントの分類」

**成果物：**
- ツールリスト（既存RPAフロー、API等）
- AIエージェントの判断ログ
- 次フェーズで自動化する業務の選定

**判断基準（次フェーズへ）：**
- AIの判断精度が80%以上
- 誤判断してもリカバリー可能な業務
- 担当者が「これなら任せられそう」と感じるレベル

---

### Phase 2：限定実行（2-3ヶ月）

**目的：** 実際に自動実行させ、運用ノウハウを蓄積

**やること：**

1. **最小構成のエージェント実装**
   - 選定した1-2業務のみ自動化
   - エージェントが使えるツールは3-5個に限定
   - 重要な操作には「人間承認」を組み込む

2. **モニタリング体制の構築**
   - 実行ログの自動記録
   - エラー時の通知
   - 週次での振り返りMTG

3. **ツール呼び出しインタフェースの標準化**
   - RPAフローをAPIとして呼び出せるようにする
   - 入力・出力の形式を統一
   - エラーハンドリングのルール化

**成果物：**
- 実運用中のAIエージェント（1-2業務）
- 運用マニュアル
- 問題事例集と対処法
- ツール呼び出しの標準仕様

**判断基準（次フェーズへ）：**
- 1ヶ月間、重大なトラブルなし
- 業務担当者が「楽になった」と実感
- コスト（API利用料）が許容範囲内

---

### Phase 3：拡大と定着（3-6ヶ月）

**目的：** 成功パターンを他業務に展開し、組織の知見として定着させる

**やること：**

1. **対象業務の拡大**
   - Phase 2で成功した業務と類似の業務から展開
   - 段階的に複雑な業務へ
   - 他部門への横展開も視野に

2. **ツールレジストリの整備（簡易版）**
   - 利用可能なツール（RPA/API等）の一覧
   - 各ツールの説明（何ができるか）
   - 利用時の注意事項

3. **ナレッジの体系化**
   - 成功パターンのドキュメント化
   - 失敗事例と対処法
   - 他部門向けの導入ガイド作成

**成果物：**
- 5-10業務の自動化実績
- ツールレジストリ（簡易版）
- 導入ガイド・ナレッジベース
- 効果測定レポート（時間削減、コスト等）

---

<br>

## 3.3 技術スタック：最小構成から始める

**過剰な設計を避ける**ため、まずは最小限の構成で開始：

### 必須コンポーネント

1. **LLM API**
   - Claude API / OpenAI API / Azure OpenAI
   - まずは1つだけ選ぶ（複数比較は後で）

2. **エージェント実行環境**
   - 選択肢A：LangChain（開発者向け）
   - 選択肢B：Microsoft AutoGen（複数エージェント）
   - 選択肢C：クラウドサービス（AWS Bedrock Agent等）

3. **ツール呼び出し層**
   - 既存RPAをAPIラッパーで包む（Power Automate、UiPath Orchestrator API等）
   - DifyアプリをAPI化
   - 既存システムのREST API

4. **ログ・モニタリング**
   - 最初は標準出力+ファイルログでOK
   - 慣れてきたらCloudWatch、Azure Monitor等

### 「後回しでいいもの」

Phase 1-2では以下は不要：

- ❌ 専用の管理画面
- ❌ 複雑な権限管理システム
- ❌ リアルタイムダッシュボード
- ❌ 複数LLMの自動切り替え
- ❌ 大規模なツールレジストリDB

---

<br>

## 3.4 ツールの「エージェント対応」方法

既存のRPA/Difyをエージェントから呼び出せるようにする**現実的な方法**：

### パターン1：RPAをAPI化

**例：UiPath Orchestrator API経由**

```python
# エージェントから見た「ツール」の定義
{
  "name": "process_invoice",
  "description": "請求書をシステムに登録する",
  "parameters": {
    "invoice_file_path": "請求書PDFのパス",
    "department": "部門名"
  }
}

# 実際の処理（ラッパー）
def process_invoice(invoice_file_path, department):
    # UiPath Orchestrator APIを呼び出し
    response = orchestrator_api.start_job(
        process_name="請求書登録RPA",
        input_arguments={
            "filePath": invoice_file_path,
            "dept": department
        }
    )
    return response.result
```

**ポイント：**
- RPAフロー自体は変更しない
- APIラッパーを薄く一枚かぶせるだけ

### パターン2：DifyアプリをAPI化

Difyは標準でAPIを提供：

```python
# エージェントから見た「ツール」の定義
{
  "name": "summarize_contract",
  "description": "契約書を要約する",
  "parameters": {
    "contract_text": "契約書の本文"
  }
}

# Dify APIを呼び出し
def summarize_contract(contract_text):
    response = requests.post(
        "https://api.dify.ai/v1/chat-messages",
        headers={"Authorization": f"Bearer {DIFY_API_KEY}"},
        json={
            "inputs": {"text": contract_text},
            "query": "この契約書を要約してください"
        }
    )
    return response.json()['answer']
```

### パターン3：既存APIをそのまま利用

```python
# エージェントから見た「ツール」の定義
{
  "name": "get_customer_info",
  "description": "顧客情報を取得する",
  "parameters": {
    "customer_id": "顧客ID"
  }
}

# 既存の顧客管理システムAPIを呼び出し
def get_customer_info(customer_id):
    response = requests.get(
        f"https://crm.company.com/api/customers/{customer_id}",
        headers={"Authorization": f"Bearer {CRM_TOKEN}"}
    )
    return response.json()
```

---

<br>

## 3.5 運用設計：理想と現実のバランス

### 理想的だが過剰な設計（Phase 1-2では不要）

- ✗ 全ツールのヘルスチェック自動化
- ✗ 詳細な状態管理（READY/DEGRADED/DISABLED等）
- ✗ リアルタイム成功率モニタリング
- ✗ 自動フェイルオーバー

### 現実的で十分な設計（まずはこれで）

**1. 手動ベースの状態管理**
- Excelやスプレッドシートでツール一覧を管理
- 「使える/使えない」のフラグを手動で更新
- エージェントは起動時にこの一覧を読み込む

**2. シンプルなエラーハンドリング**
```python
try:
    result = call_tool(tool_name, params)
except Exception as e:
    # エラーログを記録
    logger.error(f"ツール {tool_name} でエラー: {e}")
    # 担当者にメール通知
    send_alert(f"エージェントエラー: {tool_name}")
    # 人間にエスカレーション
    return "ERROR: 人間の対応が必要です"
```

**3. 週次レビュー**
- 毎週30分のMTG
- エラーログを確認
- 改善点を議論
- ツール一覧を更新

**4. 承認フローの組み込み**

重要な操作には人間承認を：

```python
if action_risk_level == "HIGH":
    # Slackで承認依頼
    approval = request_approval_via_slack(
        action=proposed_action,
        reason=agent_reasoning
    )
    if not approval.approved:
        return "操作は承認されませんでした"
```

---

<br>

## 3.6 コストと効果の考え方

### 初期コスト（Phase 1-2）

| 項目 | 概算 | 備考 |
|------|------|------|
| LLM API利用料 | 月2-5万円 | 業務量による |
| 開発工数 | 40-80時間 | 社内リソース |
| 既存ツールのAPI化 | 20-40時間 | RPAラッパー等 |
| 学習コスト | 20-40時間 | チーム全体 |

**合計：約100-160時間 + API料金**

### 期待効果（Phase 2終了時）

- **定量効果：**
  - 対象業務の処理時間 30-50%削減
  - 人的ミス 70-90%削減
  
- **定性効果：**
  - 担当者が判断業務から解放される
  - 24時間稼働可能
  - ナレッジの蓄積（エージェントの判断ログ）

### ROIの目安

月20時間削減できれば：
- 年間240時間 = 約30人日
- 人件費換算で年間150-300万円相当
- API料金を差し引いても十分にペイ

---

<br>

## 3.7 リスク管理

### 主要リスクと対策

| リスク | 影響 | 対策 |
|--------|------|------|
| AIの誤判断 | 中 | ・重要操作は人間承認<br>・ログによる事後検証 |
| APIコスト超過 | 小 | ・月次予算アラート<br>・使用量モニタリング |
| ツール側の障害 | 中 | ・エラー時は人間にエスカレーション<br>・代替手段の明示 |
| セキュリティ | 高 | ・認証情報の適切な管理<br>・最小権限の原則 |
| 担当者の抵抗 | 中 | ・段階的導入<br>・効果の可視化<br>・「支援ツール」として位置づけ |

### 「失敗」の定義と許容範囲

**Phase 1-2で許容できる失敗：**
- AIの判断精度が目標に届かない → プロンプト改善
- 特定のツールでエラー頻発 → そのツールは使わない選択も
- コストが想定より高い → 対象業務を絞る

**許容できない失敗：**
- 重大なデータ破損
- セキュリティインシデント
- 顧客への悪影響

→ これらを防ぐための**慎重な設計**が重要

---

<br>

## 3.8 成功の判断基準

### Phase 1終了時（観察と学習）

- ✓ AIの判断精度80%以上を達成
- ✓ 自動化候補業務を3つ以上特定
- ✓ チームメンバーが基本的な使い方を理解

### Phase 2終了時（限定実行）

- ✓ 1-2業務が安定稼働（1ヶ月以上）
- ✓ 重大トラブル0件
- ✓ 担当者の満足度（アンケート等）
- ✓ 運用コストが予算内

### Phase 3終了時（拡大と定着）

- ✓ 5業務以上の自動化実績
- ✓ 他部門からの引き合い
- ✓ ナレッジドキュメント整備
- ✓ 明確なROI実績
